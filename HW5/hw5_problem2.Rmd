---
title: 'HW5: Problem 2)'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

```{r}
library("jpeg")
library("plyr")
library(e1071)
library(tidyverse) # %>%
library(tree)
library(gbm)
library(randomForest)
library(glmnet)
library(ggplot2) 
library(class)
library(xgboost)
library(ggcorrplot)
library(TTR)
library(quantmod) 
```

### 1 Data preprossesing

#### (1) Get data

```{r}
getSymbols("SPY", src = "yahoo", from = as.Date("2010-01-01"), to = as.Date("2022-12-31")) 
head(SPY);
tail(SPY)
```

```{r} 
chartSeries(SPY, theme = chartTheme("white"))
```

#### (2) Data Preprocessing

I'm currently investing on stocks, so I knew some indicators. My favorites are KD and MACD, so lets introduce them into our dataset.

```{r} 
# Add MACD and RSI
macd  <- MACD(SPY[,"SPY.Close"], 12, 26, 9, maType="EMA" )
rsi <- RSI(SPY[,"SPY.Close"])

# compute daily returns:
rr <- exp(diff(log(SPY$SPY.Close)))-1
Direction <- ifelse(rr >= 0, "Up", "Down")
names(Direction) <- "Direction"

# create lag variables (you may use more lags or other info from SPY object)
rr.Lag <- Lag(rr, 1:5)
Volume.Lag <- Lag(SPY$SPY.Volume,1:5)

#For Task 1 (respones variable: rr):
SPY.return <- data.frame(rr, rr.Lag, Volume.Lag/10^9) #rescale Volume such that all scales are comparable!

SPY.return <- cbind(SPY.return, macd, rsi)
names(SPY.return) <- c("r", "r.Lag.1", "r.Lag.2", "r.Lag.3",  "r.Lag.4", "r.Lag.5", 
                       "v.Lag.1", "v.Lag.2", "v.Lag.3",  "v.Lag.4", "v.Lag.5", 
                       "macd", "signal", "rsi")

SPY.return = na.omit(SPY.return) #remove NA's
apply(SPY.return[,-1:-3],2,mean)
apply(SPY.return[,-1:-3],2,sd)

head(SPY.return)
```


```{r} 
#For Task 2 (response variable: Direction):
SPY.trend <- data.frame(Direction, rr.Lag, Volume.Lag/10^9) 
SPY.trend <- cbind(SPY.trend, macd, rsi)
names(SPY.trend) <- c("Direction", "r.Lag.1", "r.Lag.2", "r.Lag.3",  "r.Lag.4", "r.Lag.5", 
                       "v.Lag.1", "v.Lag.2", "v.Lag.3",  "v.Lag.4", "v.Lag.5", 
                       "macd", "signal", "rsi")
SPY.trend = na.omit(SPY.trend) #remove NA's
head(SPY.trend)
```

#### (3) Train-Test Split

```{r}
# Train test split
train_index2 <- seq(1,2988)

# For regression
train_reg <- SPY.return[train_index2,] # before 2021-12-31
test_reg <- SPY.return[-train_index2,] # after 2022-01-03
x_train_reg <- train_reg[,-1]
x_test_reg <- test_reg[,-1]
y_train_reg <- train_reg[,1]
y_test_reg <- test_reg[,1]

# For SVM
train_class <- SPY.trend[train_index2,] # before 2021-12-31
test_class <- SPY.trend[-train_index2,] # after 2022-01-03
x_train_class <- train_class[,-1]
y_train_class <- factor(train_class[,1])
x_test_class <- test_class[,-1]
y_test_class <- factor(test_class[,1])

# For random forest
train_dummy_X <- model.matrix(~.,train_class[,-1])[,-1]
test_dummy_X <- model.matrix(~.,test_class[,-1])[,-1]
```

### 2. Regression

#### (1) Random Forest

Since there are 14 features, I take $\texttt{mtry}=\lceil\sqrt{14}\rceil=4$.

```{r}
set.seed(1)
rf_stock <- randomForest(r ~ ., 
                         data = train_reg,
                         mtry = 4,
                         ntree = 500,
                         importance = TRUE)
rf_stock
```

```{r}
yhat.rf <- predict(rf_stock, newdata = x_test_reg)
plot(yhat.rf, y_test_reg)
abline(0, 1)
mean((yhat.rf - y_test_reg)^2)
```

The regression result looks good (MSE=0.000138).

```{r}
varImpPlot(rf_stock)
```

For MSE, yesterday's close price, RSI, MACD (along with the signal line) determines today's price. For interpret, MACD gives the moving average and trend of stock price, and RSI indicates whether the stocks go up or down to what extend.

#### (2) LASSO

```{r}
set.seed(1)
grid <- 10^seq(5, -10, length = 100) # use grid search to find lambda
cv.out <- cv.glmnet(train_dummy_X, y_train_reg, alpha = 1, nfolds=5, lambda=grid) # LASSO
plot(cv.out)
```

Choose the best LASSO $\lambda$ value.

```{r}
bestlam_lasso <- cv.out$lambda.min # best lambda
bestlam_lasso
```

```{r}
# retrain the model with the best lambda
lasso.stock <- glmnet(train_dummy_X, y_train_reg, alpha = 1, lambda = grid)

# training performance
lasso.pred <- predict(lasso.stock, s = bestlam_lasso, newx = train_dummy_X)
MSE_train <- mean((lasso.pred - y_train_reg)^2) 

# testing performance
lasso.pred <- predict(lasso.stock, s = bestlam_lasso, newx = test_dummy_X)
MSE_test <- mean((lasso.pred - y_test_reg)^2)

# results
MSE_train
MSE_test
```

The test MSE is 0.00016, it does not differs a lot from random forest.

```{r}
lasso_coeff <- predict(lasso.stock, 
                       s = bestlam_lasso, 
                       exact = T, 
                       type = "coefficients", 
                       x = train_dummy_X, 
                       y =  y_train_reg)
lasso_coeff[1:14,][which(lasso_coeff!=0)]
```

```{r}
plot(lasso.stock)
```
For LASSO, the past closed value (in 5 days) are more important than they are for random forest. Besides, the volume does not play a big role.

### 3. Classification

#### (1) SVM

```{r}
### tuning parameters (cost,gamma) via 10-fold CV
set.seed(1)
tune_stock.out <- tune(svm,
                       train.x = x_train_class,
                       train.y = y_train_class,
                       ranges = list(
                         cost = c(0.1, 1, 10, 100),
                         gamma = c(0.1, 1, 2, 3, 4),
                         kernel = 'linear',
                         scale = TRUE # Need to scale in this case
                         )
                       )
summary(tune_stock.out)
```

```{r}
###
table(true = y_test_class,
      pred = predict(tune_stock.out$best.model, newdata = x_test_class))
```

The best accuracy is 70.92%.

#### (2) Random Forest

Since there are 14 features, I take $\texttt{mtry}=\lceil\sqrt{14}\rceil=4$.

```{r}
stock_rf_class <- randomForest(x=x_train_class, 
                               y=y_train_class,
                               mtry = 4, # number of variables tried at each split
                               importance = TRUE,
                               proximity = TRUE)
plot(stock_rf_class)
```

```{r}
modfinal_rf_stock <- randomForest(x=x_train_class, 
                                  y=y_train_class, 
                                  mtry = 4, 
                                  ntree = 150, 
                                  importance = TRUE, 
                                  proximity = TRUE)
```

```{r}
table(true = y_test_class, 
      pred = predict(modfinal_rf_stock, newdata = x_test_class))
```

The accuracy is 0.74. Next, we investigate the variable importance and interpret in the summary.

```{r}
modfinal_rf_stock$importance %>% 
  as.matrix() %>% 
  as.data.frame() %>% 
  add_rownames() %>% 
  `colnames<-`(c("varname",'No','Yes',"MeanDecreaseAccuracy",'MeanDecreaseGini')) %>%
  arrange(desc(MeanDecreaseAccuracy)) %>% 
  top_n(15,wt = MeanDecreaseAccuracy) %>% 
  ggplot(aes(x = reorder(varname, MeanDecreaseAccuracy),y = MeanDecreaseAccuracy)) +
  geom_col(fill = 'steelblue', color = 'black') +
  coord_flip() +
  ggtitle(label = "Random Forest") +
  xlab('Variable') +
  ylab('MeanDecreaseAccuracy') +
  theme(plot.title=element_text(hjust=0.5,size=15),
        axis.title=element_text(size=15))
```

### 4. Summary

The accuracy is about 74% to 75% for both randomforest and SVM, to predict the value and the trend, random forest prefers the technical indicators such as RSI and MACD. However, LASSO relys a lot from past prices. The fine-tuned performance of random forest is better than SVM.

